{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import objectify\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.cbook as cbook\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'CLEAN_House2.csv'\n",
    "csvapp = pd.read_csv(path,index_col=0,parse_dates=[1])\n",
    "\n",
    "# making the index a datetime object\n",
    "import datetime as datetime\n",
    "csvapp.set_index(pd.DatetimeIndex(csvapp.index),inplace=True)\n",
    "\n",
    "clean_csv = csvapp.resample('5T').mean()\n",
    "\n",
    "clean_csv.columns = ['aggragate','fridge','washing_machine','dishwasher','TV','Microwave','Toaster','Hifi','Kettle','Fan','issues']\n",
    "clean_csv = clean_csv[clean_csv.issues == 0]\n",
    "\n",
    "# create time of day column\n",
    "cols = ['time','month','hour','minute','day_of_the_week','week','fridge','washing_machine','dishwasher','TV','Microwave','Toaster','Hifi','Kettle','Fan']\n",
    "\n",
    "usage2 = pd.DataFrame(index = clean_csv.index, columns=cols)\n",
    "\n",
    "usage2.hour = clean_csv.index.hour\n",
    "usage2.minute = clean_csv.index.minute\n",
    "\n",
    "usage2.month=clean_csv.index.month\n",
    "\n",
    "usage2.day_of_the_week = clean_csv.index.dayofweek\n",
    "usage2.time = clean_csv.index.hour*60+clean_csv.index.minute\n",
    "\n",
    "usage2.week = clean_csv.index.week\n",
    "\n",
    "usage2.fillna(0, inplace = True)\n",
    "\n",
    "usage2.TV[(clean_csv.TV > 20)] = 1\n",
    "\n",
    "usage2.Kettle[(clean_csv.Kettle > 20)] =1\n",
    "\n",
    "usage2.Microwave[(clean_csv.Microwave>15)] =1\n",
    "\n",
    "usage2.Toaster[(clean_csv.Toaster > 15)] = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Microwave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undersampled RTF\n",
      "0.8028846153846154\n",
      "0.8020304568527918 \n",
      "\n",
      "Under KNN\n",
      "0.6730769230769231\n",
      "0.8121827411167513 \n",
      "\n",
      "Under logreg\n",
      "0.5841346153846154\n",
      "0.6395939086294417 \n",
      "\n",
      "Under Bagging\n",
      "0.7956730769230769\n",
      "0.7614213197969543 \n",
      "\n",
      "Over RTF\n",
      "0.9612732264861759\n",
      "0.419811320754717\n",
      "\n",
      "Over KNN\n",
      "0.8831492241874721\n",
      "0.5188679245283019\n",
      "\n",
      "Over Logreg\n",
      "0.5916927399272077\n",
      "0.589622641509434\n",
      "Over Bagging\n",
      "0.9587829640508269\n",
      "0.42452830188679247\n",
      "\n",
      "RTF\n",
      "0.9907413319711385\n",
      "0.08490566037735849\n",
      "\n",
      "KNN\n",
      "0.9932315944064875\n",
      "0.0\n",
      "\n",
      "logreg\n",
      "0.9932315944064875\n",
      "0.0\n",
      "\n",
      "bagging\n",
      "0.9907094055296597\n",
      "0.09433962264150944\n"
     ]
    }
   ],
   "source": [
    "## undersample\n",
    "\n",
    "ones = len(usage2.Microwave[(usage2.Microwave == 1)])\n",
    "zero_indices = usage2[usage2.Microwave == 0].index\n",
    "random_indices = np.random.choice(zero_indices,ones, replace=False)\n",
    "ones = usage2[usage2.Microwave == 1].index\n",
    "under_sample_indices = np.concatenate([ones,random_indices])\n",
    "under_sample = usage2.loc[under_sample_indices]\n",
    "\n",
    "cols = ['month','hour','minute','day_of_the_week','week']\n",
    "\n",
    "X = under_sample[cols]\n",
    "y = under_sample.Microwave\n",
    "\n",
    "under_sample = usage2.loc[under_sample_indices]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "\n",
    "#### RTF\n",
    "\n",
    "clf_rf = RandomForestClassifier(n_estimators=25, random_state=12)\n",
    "clf_rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_class = clf_rf.predict(X_test)\n",
    "print('Undersampled RTF')\n",
    "print(accuracy_score(y_test, y_pred_class))\n",
    "print(recall_score(y_test, y_pred_class),'\\n')\n",
    "\n",
    "\n",
    "#### KNN\n",
    "\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=20)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_class = knn.predict(X_test)\n",
    "print('Under KNN')\n",
    "print(accuracy_score(y_test, y_pred_class))\n",
    "print(recall_score(y_test, y_pred_class),'\\n')\n",
    "\n",
    "#### Logistic regression\n",
    "\n",
    "logr =LogisticRegression(solver = 'lbfgs')\n",
    "logr.fit(X_train,y_train)\n",
    "y_pred_class = logr.predict(X_test)\n",
    "print('Under logreg')\n",
    "print(accuracy_score(y_test, y_pred_class))\n",
    "print(recall_score(y_test, y_pred_class),'\\n')\n",
    "\n",
    "#### Bagging\n",
    "\n",
    "bg = BaggingClassifier()\n",
    "bg.fit(X_train,y_train)\n",
    "y_pred_class = bg.predict(X_test)\n",
    "print('Under Bagging')\n",
    "print(accuracy_score(y_test, y_pred_class))\n",
    "print(recall_score(y_test, y_pred_class),'\\n')\n",
    "\n",
    "## Over sample\n",
    "\n",
    "cols = ['month','hour','minute','day_of_the_week','week']\n",
    "X = usage2[cols]\n",
    "y = usage2.Microwave\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "sm = SMOTE(random_state=12, ratio = 1.0)\n",
    "X_train_res, y_train_res = sm.fit_sample(X_train, y_train)\n",
    "\n",
    "#### RTF\n",
    "\n",
    "\n",
    "clf_rf = RandomForestClassifier(n_estimators=25, random_state=12)\n",
    "clf_rf.fit(X_train_res, y_train_res)\n",
    "\n",
    "y_pred_class = clf_rf.predict(X_test)\n",
    "print('Over RTF')\n",
    "print(accuracy_score(y_test, y_pred_class))\n",
    "print(recall_score(y_test, y_pred_class))\n",
    "print('')\n",
    "\n",
    "\n",
    "#### KNN\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=20)\n",
    "knn.fit(X_train_res, y_train_res)\n",
    "y_pred_class = knn.predict(X_test)\n",
    "print('Over KNN')\n",
    "print(accuracy_score(y_test, y_pred_class))\n",
    "print(recall_score(y_test, y_pred_class))\n",
    "print('')\n",
    "#### Logistic regression\n",
    "\n",
    "logr =LogisticRegression(solver = 'lbfgs')\n",
    "logr.fit(X_train_res,y_train_res)\n",
    "y_pred_class = logr.predict(X_test)\n",
    "print('Over Logreg')\n",
    "print(accuracy_score(y_test, y_pred_class))\n",
    "print(recall_score(y_test, y_pred_class))\n",
    "\n",
    "#### Bagging\n",
    "\n",
    "bg = BaggingClassifier()\n",
    "bg.fit(X_train_res,y_train_res)\n",
    "y_pred_class = bg.predict(X_test)\n",
    "print('Over Bagging')\n",
    "print(accuracy_score(y_test, y_pred_class))\n",
    "print(recall_score(y_test, y_pred_class))\n",
    "print('')\n",
    "## Regular\n",
    "\n",
    "\n",
    "cols = ['month','hour','minute','day_of_the_week','week']\n",
    "X = usage2[cols]\n",
    "y = usage2.Microwave\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "\n",
    "#### RTF\n",
    "\n",
    "clf_rf = RandomForestClassifier(n_estimators=25, random_state=12)\n",
    "clf_rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_class = clf_rf.predict(X_test)\n",
    "print('RTF')\n",
    "print(accuracy_score(y_test, y_pred_class))\n",
    "print(recall_score(y_test, y_pred_class))\n",
    "print('')\n",
    "\n",
    "#### KNN \n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=20)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_class = knn.predict(X_test)\n",
    "print('KNN')\n",
    "print(accuracy_score(y_test, y_pred_class))\n",
    "print(recall_score(y_test, y_pred_class))\n",
    "print('')\n",
    "#### Logistic regression\n",
    "\n",
    "logr =LogisticRegression(solver = 'lbfgs')\n",
    "logr.fit(X_train,y_train)\n",
    "y_pred_class = logr.predict(X_test)\n",
    "print('logreg')\n",
    "print(accuracy_score(y_test, y_pred_class))\n",
    "print(recall_score(y_test, y_pred_class))\n",
    "print('')\n",
    "#### Bagging\n",
    "\n",
    "bg = BaggingClassifier()\n",
    "bg.fit(X_train,y_train)\n",
    "y_pred_class = bg.predict(X_test)\n",
    "print('bagging')\n",
    "print(accuracy_score(y_test, y_pred_class))\n",
    "print(recall_score(y_test, y_pred_class))\n",
    "\n",
    "#### Bagging\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undersampled RTF\n",
      "0.8740993553280243\n",
      "0.9134687735139202 \n",
      "\n",
      "Under KNN\n",
      "0.6839211224876753\n",
      "0.7562076749435666 \n",
      "\n",
      "Under logreg\n",
      "0.5515737580583997\n",
      "0.5654627539503386 \n",
      "\n",
      "Under Bagging\n",
      "0.8593098217671596\n",
      "0.8792325056433409 \n",
      "\n",
      "Over RTF\n",
      "0.8626524487580615\n",
      "0.6757176105508146\n",
      "\n",
      "Over KNN\n",
      "0.7480684502905306\n",
      "0.7106283941039565\n",
      "\n",
      "Over Logreg\n",
      "0.5451120618095907\n",
      "0.54344453064391\n",
      "Over Bagging\n",
      "0.85968328970053\n",
      "0.6625290923196276\n",
      "\n",
      "RTF\n",
      "0.9280697273481898\n",
      "0.4712955779674166\n",
      "\n",
      "KNN\n",
      "0.918268309814188\n",
      "0.02948021722265322\n",
      "\n",
      "logreg\n",
      "0.9176936338675691\n",
      "0.0\n",
      "\n",
      "bagging\n",
      "0.9309111806398059\n",
      "0.5100853374709077\n"
     ]
    }
   ],
   "source": [
    "## undersample\n",
    "\n",
    "ones = len(usage2.TV[(usage2.TV == 1)])\n",
    "zero_indices = usage2[usage2.TV == 0].index\n",
    "random_indices = np.random.choice(zero_indices,ones, replace=False)\n",
    "ones = usage2[usage2.TV == 1].index\n",
    "under_sample_indices = np.concatenate([ones,random_indices])\n",
    "under_sample = usage2.loc[under_sample_indices]\n",
    "\n",
    "cols = ['month','hour','minute','day_of_the_week','week']\n",
    "\n",
    "X = under_sample[cols]\n",
    "y = under_sample.TV\n",
    "\n",
    "under_sample = usage2.loc[under_sample_indices]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "\n",
    "#### RTF\n",
    "\n",
    "clf_rf = RandomForestClassifier(n_estimators=25, random_state=12)\n",
    "clf_rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_class = clf_rf.predict(X_test)\n",
    "print('Undersampled RTF')\n",
    "print(accuracy_score(y_test, y_pred_class))\n",
    "print(recall_score(y_test, y_pred_class),'\\n')\n",
    "\n",
    "\n",
    "#### KNN\n",
    "\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=20)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_class = knn.predict(X_test)\n",
    "print('Under KNN')\n",
    "print(accuracy_score(y_test, y_pred_class))\n",
    "print(recall_score(y_test, y_pred_class),'\\n')\n",
    "\n",
    "#### Logistic regression\n",
    "\n",
    "logr =LogisticRegression(solver = 'lbfgs')\n",
    "logr.fit(X_train,y_train)\n",
    "y_pred_class = logr.predict(X_test)\n",
    "print('Under logreg')\n",
    "print(accuracy_score(y_test, y_pred_class))\n",
    "print(recall_score(y_test, y_pred_class),'\\n')\n",
    "\n",
    "#### Bagging\n",
    "\n",
    "bg = BaggingClassifier()\n",
    "bg.fit(X_train,y_train)\n",
    "y_pred_class = bg.predict(X_test)\n",
    "print('Under Bagging')\n",
    "print(accuracy_score(y_test, y_pred_class))\n",
    "print(recall_score(y_test, y_pred_class),'\\n')\n",
    "\n",
    "## Over sample\n",
    "\n",
    "cols = ['month','hour','minute','day_of_the_week','week']\n",
    "X = usage2[cols]\n",
    "y = usage2.TV\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "sm = SMOTE(random_state=12, ratio = 1.0)\n",
    "X_train_res, y_train_res = sm.fit_sample(X_train, y_train)\n",
    "\n",
    "#### RTF\n",
    "\n",
    "\n",
    "clf_rf = RandomForestClassifier(n_estimators=25, random_state=12)\n",
    "clf_rf.fit(X_train_res, y_train_res)\n",
    "\n",
    "y_pred_class = clf_rf.predict(X_test)\n",
    "print('Over RTF')\n",
    "print(accuracy_score(y_test, y_pred_class))\n",
    "print(recall_score(y_test, y_pred_class))\n",
    "print('')\n",
    "\n",
    "\n",
    "#### KNN\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=20)\n",
    "knn.fit(X_train_res, y_train_res)\n",
    "y_pred_class = knn.predict(X_test)\n",
    "print('Over KNN')\n",
    "print(accuracy_score(y_test, y_pred_class))\n",
    "print(recall_score(y_test, y_pred_class))\n",
    "print('')\n",
    "#### Logistic regression\n",
    "\n",
    "logr =LogisticRegression(solver = 'lbfgs')\n",
    "logr.fit(X_train_res,y_train_res)\n",
    "y_pred_class = logr.predict(X_test)\n",
    "print('Over Logreg')\n",
    "print(accuracy_score(y_test, y_pred_class))\n",
    "print(recall_score(y_test, y_pred_class))\n",
    "\n",
    "#### Bagging\n",
    "\n",
    "bg = BaggingClassifier()\n",
    "bg.fit(X_train_res,y_train_res)\n",
    "y_pred_class = bg.predict(X_test)\n",
    "print('Over Bagging')\n",
    "print(accuracy_score(y_test, y_pred_class))\n",
    "print(recall_score(y_test, y_pred_class))\n",
    "print('')\n",
    "## Regular\n",
    "\n",
    "\n",
    "cols = ['month','hour','minute','day_of_the_week','week']\n",
    "X = usage2[cols]\n",
    "y = usage2.TV\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "\n",
    "#### RTF\n",
    "\n",
    "clf_rf = RandomForestClassifier(n_estimators=25, random_state=12)\n",
    "clf_rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_class = clf_rf.predict(X_test)\n",
    "print('RTF')\n",
    "print(accuracy_score(y_test, y_pred_class))\n",
    "print(recall_score(y_test, y_pred_class))\n",
    "print('')\n",
    "\n",
    "#### KNN \n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=20)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_class = knn.predict(X_test)\n",
    "print('KNN')\n",
    "print(accuracy_score(y_test, y_pred_class))\n",
    "print(recall_score(y_test, y_pred_class))\n",
    "print('')\n",
    "#### Logistic regression\n",
    "\n",
    "logr =LogisticRegression(solver = 'lbfgs')\n",
    "logr.fit(X_train,y_train)\n",
    "y_pred_class = logr.predict(X_test)\n",
    "print('logreg')\n",
    "print(accuracy_score(y_test, y_pred_class))\n",
    "print(recall_score(y_test, y_pred_class))\n",
    "print('')\n",
    "#### Bagging\n",
    "\n",
    "bg = BaggingClassifier()\n",
    "bg.fit(X_train,y_train)\n",
    "y_pred_class = bg.predict(X_test)\n",
    "print('bagging')\n",
    "print(accuracy_score(y_test, y_pred_class))\n",
    "print(recall_score(y_test, y_pred_class))\n",
    "\n",
    "#### Bagging\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undersampled RTF\n",
      "0.6981132075471698\n",
      "0.7162162162162162 \n",
      "\n",
      "Under KNN\n",
      "0.5974842767295597\n",
      "0.6351351351351351 \n",
      "\n",
      "Under logreg\n",
      "0.5723270440251572\n",
      "0.6891891891891891 \n",
      "\n",
      "Under Bagging\n",
      "0.7295597484276729\n",
      "0.7297297297297297 \n",
      "\n",
      "Over RTF\n",
      "0.9754166400612988\n",
      "0.06741573033707865\n",
      "\n",
      "Over KNN\n",
      "0.9082114807483558\n",
      "0.12359550561797752\n",
      "\n",
      "Over Logreg\n",
      "0.5620650022348509\n",
      "0.34831460674157305\n",
      "Over Bagging\n",
      "0.9733414213651747\n",
      "0.07865168539325842\n",
      "\n",
      "RTF\n",
      "0.9962965327884554\n",
      "0.0449438202247191\n",
      "\n",
      "KNN\n",
      "0.9971585467083839\n",
      "0.0\n",
      "\n",
      "logreg\n",
      "0.9971585467083839\n",
      "0.0\n",
      "\n",
      "bagging\n",
      "0.9964561649958495\n",
      "0.11235955056179775\n"
     ]
    }
   ],
   "source": [
    "## undersample\n",
    "\n",
    "ones = len(usage2.Toaster[(usage2.Toaster == 1)])\n",
    "zero_indices = usage2[usage2.Toaster == 0].index\n",
    "random_indices = np.random.choice(zero_indices,ones, replace=False)\n",
    "ones = usage2[usage2.Toaster == 1].index\n",
    "under_sample_indices = np.concatenate([ones,random_indices])\n",
    "under_sample = usage2.loc[under_sample_indices]\n",
    "\n",
    "cols = ['month','hour','minute','day_of_the_week','week']\n",
    "\n",
    "X = under_sample[cols]\n",
    "y = under_sample.Toaster\n",
    "\n",
    "under_sample = usage2.loc[under_sample_indices]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "\n",
    "#### RTF\n",
    "\n",
    "clf_rf = RandomForestClassifier(n_estimators=25, random_state=12)\n",
    "clf_rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_class = clf_rf.predict(X_test)\n",
    "print('Undersampled RTF')\n",
    "print(accuracy_score(y_test, y_pred_class))\n",
    "print(recall_score(y_test, y_pred_class),'\\n')\n",
    "\n",
    "\n",
    "#### KNN\n",
    "\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=20)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_class = knn.predict(X_test)\n",
    "print('Under KNN')\n",
    "print(accuracy_score(y_test, y_pred_class))\n",
    "print(recall_score(y_test, y_pred_class),'\\n')\n",
    "\n",
    "#### Logistic regression\n",
    "\n",
    "logr =LogisticRegression(solver = 'lbfgs')\n",
    "logr.fit(X_train,y_train)\n",
    "y_pred_class = logr.predict(X_test)\n",
    "print('Under logreg')\n",
    "print(accuracy_score(y_test, y_pred_class))\n",
    "print(recall_score(y_test, y_pred_class),'\\n')\n",
    "\n",
    "#### Bagging\n",
    "\n",
    "bg = BaggingClassifier()\n",
    "bg.fit(X_train,y_train)\n",
    "y_pred_class = bg.predict(X_test)\n",
    "print('Under Bagging')\n",
    "print(accuracy_score(y_test, y_pred_class))\n",
    "print(recall_score(y_test, y_pred_class),'\\n')\n",
    "\n",
    "## Over sample\n",
    "\n",
    "cols = ['month','hour','minute','day_of_the_week','week']\n",
    "X = usage2[cols]\n",
    "y = usage2.Toaster\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "sm = SMOTE(random_state=12, ratio = 1.0)\n",
    "X_train_res, y_train_res = sm.fit_sample(X_train, y_train)\n",
    "\n",
    "#### RTF\n",
    "\n",
    "\n",
    "clf_rf = RandomForestClassifier(n_estimators=25, random_state=12)\n",
    "clf_rf.fit(X_train_res, y_train_res)\n",
    "\n",
    "y_pred_class = clf_rf.predict(X_test)\n",
    "print('Over RTF')\n",
    "print(accuracy_score(y_test, y_pred_class))\n",
    "print(recall_score(y_test, y_pred_class))\n",
    "print('')\n",
    "\n",
    "\n",
    "#### KNN\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=20)\n",
    "knn.fit(X_train_res, y_train_res)\n",
    "y_pred_class = knn.predict(X_test)\n",
    "print('Over KNN')\n",
    "print(accuracy_score(y_test, y_pred_class))\n",
    "print(recall_score(y_test, y_pred_class))\n",
    "print('')\n",
    "#### Logistic regression\n",
    "\n",
    "logr =LogisticRegression(solver = 'lbfgs')\n",
    "logr.fit(X_train_res,y_train_res)\n",
    "y_pred_class = logr.predict(X_test)\n",
    "print('Over Logreg')\n",
    "print(accuracy_score(y_test, y_pred_class))\n",
    "print(recall_score(y_test, y_pred_class))\n",
    "\n",
    "#### Bagging\n",
    "\n",
    "bg = BaggingClassifier()\n",
    "bg.fit(X_train_res,y_train_res)\n",
    "y_pred_class = bg.predict(X_test)\n",
    "print('Over Bagging')\n",
    "print(accuracy_score(y_test, y_pred_class))\n",
    "print(recall_score(y_test, y_pred_class))\n",
    "print('')\n",
    "## Regular\n",
    "\n",
    "\n",
    "cols = ['month','hour','minute','day_of_the_week','week']\n",
    "X = usage2[cols]\n",
    "y = usage2.Toaster\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "\n",
    "#### RTF\n",
    "\n",
    "clf_rf = RandomForestClassifier(n_estimators=25, random_state=12)\n",
    "clf_rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_class = clf_rf.predict(X_test)\n",
    "print('RTF')\n",
    "print(accuracy_score(y_test, y_pred_class))\n",
    "print(recall_score(y_test, y_pred_class))\n",
    "print('')\n",
    "\n",
    "#### KNN \n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=20)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_class = knn.predict(X_test)\n",
    "print('KNN')\n",
    "print(accuracy_score(y_test, y_pred_class))\n",
    "print(recall_score(y_test, y_pred_class))\n",
    "print('')\n",
    "#### Logistic regression\n",
    "\n",
    "logr =LogisticRegression(solver = 'lbfgs')\n",
    "logr.fit(X_train,y_train)\n",
    "y_pred_class = logr.predict(X_test)\n",
    "print('logreg')\n",
    "print(accuracy_score(y_test, y_pred_class))\n",
    "print(recall_score(y_test, y_pred_class))\n",
    "print('')\n",
    "#### Bagging\n",
    "\n",
    "bg = BaggingClassifier()\n",
    "bg.fit(X_train,y_train)\n",
    "y_pred_class = bg.predict(X_test)\n",
    "print('bagging')\n",
    "print(accuracy_score(y_test, y_pred_class))\n",
    "print(recall_score(y_test, y_pred_class))\n",
    "\n",
    "#### Bagging\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kettle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undersampled RTF\n",
      "0.72480181200453\n",
      "0.7738359201773836 \n",
      "\n",
      "Under KNN\n",
      "0.6568516421291053\n",
      "0.6829268292682927 \n",
      "\n",
      "Under logreg\n",
      "0.578708946772367\n",
      "0.6008869179600886 \n",
      "\n",
      "Under Bagging\n",
      "0.7089467723669309\n",
      "0.7117516629711752 \n",
      "\n",
      "Over RTF\n",
      "0.9072856139454697\n",
      "0.2296983758700696\n",
      "\n",
      "Over KNN\n",
      "0.7939148202541345\n",
      "0.41299303944315546\n",
      "\n",
      "Over Logreg\n",
      "0.5637890300747078\n",
      "0.5661252900232019\n",
      "Over Bagging\n",
      "0.9027201328139965\n",
      "0.22273781902552203\n",
      "\n",
      "RTF\n",
      "0.9815145903837559\n",
      "0.013921113689095127\n",
      "\n",
      "KNN\n",
      "0.986239703722623\n",
      "0.0\n",
      "\n",
      "logreg\n",
      "0.986239703722623\n",
      "0.0\n",
      "\n",
      "bagging\n",
      "0.9815145903837559\n",
      "0.04408352668213457\n"
     ]
    }
   ],
   "source": [
    "## undersample\n",
    "\n",
    "ones = len(usage2.Kettle[(usage2.Kettle == 1)])\n",
    "zero_indices = usage2[usage2.Kettle == 0].index\n",
    "random_indices = np.random.choice(zero_indices,ones, replace=False)\n",
    "ones = usage2[usage2.Kettle == 1].index\n",
    "under_sample_indices = np.concatenate([ones,random_indices])\n",
    "under_sample = usage2.loc[under_sample_indices]\n",
    "\n",
    "cols = ['month','hour','minute','day_of_the_week','week']\n",
    "\n",
    "X = under_sample[cols]\n",
    "y = under_sample.Kettle\n",
    "\n",
    "under_sample = usage2.loc[under_sample_indices]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "\n",
    "#### RTF\n",
    "\n",
    "clf_rf = RandomForestClassifier(n_estimators=25, random_state=12)\n",
    "clf_rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_class = clf_rf.predict(X_test)\n",
    "print('Undersampled RTF')\n",
    "print(accuracy_score(y_test, y_pred_class))\n",
    "print(recall_score(y_test, y_pred_class),'\\n')\n",
    "\n",
    "\n",
    "#### KNN\n",
    "\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=20)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_class = knn.predict(X_test)\n",
    "print('Under KNN')\n",
    "print(accuracy_score(y_test, y_pred_class))\n",
    "print(recall_score(y_test, y_pred_class),'\\n')\n",
    "\n",
    "#### Logistic regression\n",
    "\n",
    "logr =LogisticRegression(solver = 'lbfgs')\n",
    "logr.fit(X_train,y_train)\n",
    "y_pred_class = logr.predict(X_test)\n",
    "print('Under logreg')\n",
    "print(accuracy_score(y_test, y_pred_class))\n",
    "print(recall_score(y_test, y_pred_class),'\\n')\n",
    "\n",
    "#### Bagging\n",
    "\n",
    "bg = BaggingClassifier()\n",
    "bg.fit(X_train,y_train)\n",
    "y_pred_class = bg.predict(X_test)\n",
    "print('Under Bagging')\n",
    "print(accuracy_score(y_test, y_pred_class))\n",
    "print(recall_score(y_test, y_pred_class),'\\n')\n",
    "\n",
    "## Over sample\n",
    "\n",
    "cols = ['month','hour','minute','day_of_the_week','week']\n",
    "X = usage2[cols]\n",
    "y = usage2.Kettle\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "sm = SMOTE(random_state=12, ratio = 1.0)\n",
    "X_train_res, y_train_res = sm.fit_sample(X_train, y_train)\n",
    "\n",
    "#### RTF\n",
    "\n",
    "\n",
    "clf_rf = RandomForestClassifier(n_estimators=25, random_state=12)\n",
    "clf_rf.fit(X_train_res, y_train_res)\n",
    "\n",
    "y_pred_class = clf_rf.predict(X_test)\n",
    "print('Over RTF')\n",
    "print(accuracy_score(y_test, y_pred_class))\n",
    "print(recall_score(y_test, y_pred_class))\n",
    "print('')\n",
    "\n",
    "\n",
    "#### KNN\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=20)\n",
    "knn.fit(X_train_res, y_train_res)\n",
    "y_pred_class = knn.predict(X_test)\n",
    "print('Over KNN')\n",
    "print(accuracy_score(y_test, y_pred_class))\n",
    "print(recall_score(y_test, y_pred_class))\n",
    "print('')\n",
    "#### Logistic regression\n",
    "\n",
    "logr =LogisticRegression(solver = 'lbfgs')\n",
    "logr.fit(X_train_res,y_train_res)\n",
    "y_pred_class = logr.predict(X_test)\n",
    "print('Over Logreg')\n",
    "print(accuracy_score(y_test, y_pred_class))\n",
    "print(recall_score(y_test, y_pred_class))\n",
    "\n",
    "#### Bagging\n",
    "\n",
    "bg = BaggingClassifier()\n",
    "bg.fit(X_train_res,y_train_res)\n",
    "y_pred_class = bg.predict(X_test)\n",
    "print('Over Bagging')\n",
    "print(accuracy_score(y_test, y_pred_class))\n",
    "print(recall_score(y_test, y_pred_class))\n",
    "print('')\n",
    "## Regular\n",
    "\n",
    "\n",
    "cols = ['month','hour','minute','day_of_the_week','week']\n",
    "X = usage2[cols]\n",
    "y = usage2.Kettle\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "\n",
    "#### RTF\n",
    "\n",
    "clf_rf = RandomForestClassifier(n_estimators=25, random_state=12)\n",
    "clf_rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_class = clf_rf.predict(X_test)\n",
    "print('RTF')\n",
    "print(accuracy_score(y_test, y_pred_class))\n",
    "print(recall_score(y_test, y_pred_class))\n",
    "print('')\n",
    "\n",
    "#### KNN \n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=20)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_class = knn.predict(X_test)\n",
    "print('KNN')\n",
    "print(accuracy_score(y_test, y_pred_class))\n",
    "print(recall_score(y_test, y_pred_class))\n",
    "print('')\n",
    "#### Logistic regression\n",
    "\n",
    "logr =LogisticRegression(solver = 'lbfgs')\n",
    "logr.fit(X_train,y_train)\n",
    "y_pred_class = logr.predict(X_test)\n",
    "print('logreg')\n",
    "print(accuracy_score(y_test, y_pred_class))\n",
    "print(recall_score(y_test, y_pred_class))\n",
    "print('')\n",
    "#### Bagging\n",
    "\n",
    "bg = BaggingClassifier()\n",
    "bg.fit(X_train,y_train)\n",
    "y_pred_class = bg.predict(X_test)\n",
    "print('bagging')\n",
    "print(accuracy_score(y_test, y_pred_class))\n",
    "print(recall_score(y_test, y_pred_class))\n",
    "\n",
    "#### Bagging\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
